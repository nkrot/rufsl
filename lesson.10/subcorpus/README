-*- UTF-8; -*-

Входные данные для всех нижеуказанных скриптов находятся в файле corpus.tok.txt:
	data/corpus.tok.txt
	lesson.09.tasks/subcorpus/corpus.tok.txt
Файл содержит токенизированные предложения (полученные при помощи syn_p2w --line | syn_w2s), каждое предложение находится на отдельной строке.


Задание 1
=========

Разработать скрипт, который из данного файла выделяет ~10 % предложений, выбирая каждое десятое предложение.

Ожидаемый выход 2645 предложений: extract_nth_sentence.out

Ответ: lesson.10/subcorpus/extract_nth_sentence.rb


Задание 2
=========

Необходимо разработать скрипт, который из данного файла случайным образом выделяет 10 % предложений. Дубликаты в выдаче допустимы, только если предложения дублируются в исходном файле. Ниже будет описано, как проверить дубликаты.

Поскольку выборка осуществляется случайным образом, эталонного выхода быть не может.
Примерный выход содержит 2645 предложений: extract_random_subcorpus.out

Ответ: lesson.10/subcorpus/extract_random_subcorpus.rb

Задание 3
==========

Как предыдущее задание, но необходимо сохранить в выдаче оригинальный порядок предложений.

Примерный выход содержит 2645 строк: extract_random_subcorpus.2.out
Ответ: lesson.10/subcorpus/extract_random_subcorpus.2.rb

Проверить совпадение порядка строк в двух файлах можно следующим образом:

	> diff corpus.tok.txt extract_random_subcorpus.out | grep '^>'


Для решения этой задачи **возможно** вам пригодится splat operator.

	* is the splat operator. It is used to split an array into a list of arguments.

Где он используется. Представьте, что у вас есть метод, который принимает 3 аргумента

	> "hello world".my_cool_method(arg1, arg2, arg3)

но в данный момент времени все аргументы каким-то образом оказались собраны в один массив:

	> my_args = [arg1, arg2, arg3]

Тогда необходимо использовать оператор splat, чтобы массив преобразовать в отдельные аргументы и вызвать тот самый трех аргументный метод:

	> "hello world".my_cool_method(*my_args)

Проверка дубликатов
===================

Необходимо убедиться, что дубликаты в выборке действительно являются дубликатами в исходном тексте.

Шаг 1: необходимо выделить дубликаты из выборки:

	> cat output_file | sort | uniq -d

Шаг 2: необходимо убедиться, что выведенные предложения присутствуют в исходном файле corpus.tok.txt несколько раз. Выберите какой-нибудь пример и выполните для него:

	> cat corpus.tok.txt | grep -Fx "какой-нибудь пример из шага 1"

Вы должны увидеть больше одной строки.

Потренируйтесь на этом примере:

	> grep -Fx 'Reuters contributed to this report .' corpus.tok.txt
	> grep -Fx 'Reuters contributed to this report'
	> grep -Fx 'Reuters contributed to this'

Можно не мелочиться и сделать проверку всех дубликатов сразу:

Шаг 1: выбрать дубликаты из выборки и сохранить в файл

	>  cat output_file | sort | uniq -d >dups.txt

Шаг 2: проверить, что в исходном корпусе эти строки встречаются несколько раз:

	> cat corpus.tok.txt | grep -Fxf dups | sort | uniq -u

выведет строки, которые были найдены только один раз (таких строк не должно быть). Вместо -u можно использовать -с, это тоже наглядно, но требует ручного (caveat: разве можно смотреть руками?) просмотра.

Enjoy programming

